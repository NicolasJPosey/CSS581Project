{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a927d55-1850-4698-b6ae-e8bbae2c7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic_regression\n",
      "Accuracy: 0.833\n",
      "Precision: 1.0\n",
      "Recall: 0.583\n",
      "F-score: 0.737\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def runModels(X_train, y_train, X_test, y_test, mode):\n",
    "    if (mode == 'logistic_regression'):\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    elif (mode == 'naive_bayes'):\n",
    "        model = GaussianNB()\n",
    "    elif (mode == 'knn'):\n",
    "        model = 1\n",
    "    elif (mode == 'decision_tree'):\n",
    "        model = 1\n",
    "    elif (mode == 'random_forest'):\n",
    "        model = RandomForestClassifier(max_depth=2,random_state=1)\n",
    "    elif (mode == 'svm'):\n",
    "        model = 1\n",
    "    \n",
    "    scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train=scaler.transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    \n",
    "    print(\"Model:\",mode)\n",
    "    print(\"Accuracy:\",round(accuracy_score(y_test, y_pred),3))\n",
    "    print(\"Precision:\",round(precision_score(y_test, y_pred),3))\n",
    "    print(\"Recall:\",round(recall_score(y_test, y_pred),3))\n",
    "    print(\"F-score:\",round(f1_score(y_test, y_pred),3))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #For calculating missing OOBP and OSLG\n",
    "    #https://imaginesports.com/bball/reference/stats101/popup#:~:text=OOBP%20%E2%80%93%20Opponents%20On%20Base%20Percentage,OAVG%2B%20%E2%80%93%20Normalized%20Opponents%20Batting%20Average.\n",
    "    dataframe = pandas.read_csv(\"Final_2022_1962_Dataset.csv\",delimiter=',',header=0)\n",
    "    dataframe.drop(\"RankSeason\",axis=1,inplace=True)\n",
    "    dataframe.drop(\"RankPlayoffs\",axis=1,inplace=True)\n",
    "    dataframe['Win_Percentage'] = dataframe.apply(lambda x: round(x['W']/x['G'],3),axis=1)\n",
    "    dataframe.drop(\"W\",axis=1,inplace=True)\n",
    "    dataframe.drop(\"G\",axis=1,inplace=True)\n",
    "    dataframe.drop(\"Team\",axis=1,inplace=True)\n",
    "    dataframe.drop(\"League\",axis=1,inplace=True)\n",
    "    dataframe.drop(\"Year\",axis=1,inplace=True)\n",
    "    \n",
    "    #Get 1962 to 2021 teams for training\n",
    "    train = dataframe.iloc[30:]\n",
    "    #Get 2022 teams for testing\n",
    "    test = dataframe.iloc[:30]\n",
    "\n",
    "    X_train=train.drop(\"Playoffs\",axis=1)\n",
    "    y_train=numpy.ravel(train['Playoffs'])\n",
    "    X_test=test.drop(\"Playoffs\",axis=1)\n",
    "    y_test=numpy.ravel(test['Playoffs'])\n",
    "    \n",
    "    #Define the classification models that we want to try to see which has the best results\n",
    "    #,'naive_bayes','knn','decision_tree','random_forest','svm'\n",
    "    classificationModels = ['logistic_regression']\n",
    "    \n",
    "    for model in classificationModels:\n",
    "        runModels(X_train, y_train, X_test, y_test, model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae63c23-d951-492a-b919-be289cea2cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1421831970528/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1421831970528/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show,show_link\n",
    "\n",
    "feature_types=['continuous','continuous','continuous','continuous','continuous','continuous','continuous',\n",
    "               'continuous','continuous']\n",
    "ebm = ExplainableBoostingClassifier(feature_types=feature_types,random_state=1)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981619b-65c5-4e49-8da4-4a8fc5670400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
